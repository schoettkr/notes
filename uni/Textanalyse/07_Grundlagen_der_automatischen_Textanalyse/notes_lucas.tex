% Created 2018-06-03 Sun 14:28
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\date{\today}
\title{}
\hypersetup{
 pdfauthor={},
 pdftitle={},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 26.0.91 (Org mode 9.1.13)}, 
 pdflang={English}}
\begin{document}

\tableofcontents

\section{Computer-Assisted Text Analysis for Comparative Politics}
\label{sec:org0e95a2d}
\section{Introduction}
\label{sec:org86c6b4e}
\begin{itemize}
\item Fokus auf Tools für Komparatisten, um \emph{textual} data zu nutzen
\item Hervorhebung des \emph{unsupervised topic modeling}
\item Verwendung des Structural Topic Model um das Potential von Topic Modeling für vergleichende Politik aufzuzeigen
\begin{itemize}
\item STM erlaubt Rückschlüsse auf Beziehung zw Metadaten und Textkorpus
\end{itemize}
\item wie unterscheidet sich Textanalyse und Text Processing in versch Sprachen
\begin{itemize}
\item R package `translateR`
\end{itemize}
\end{itemize}
\section{Text and Language Basics}
\label{sec:orgce02cc3}
\subsection{Research Questions and Data Analysis}
\label{sec:org6c3b24c}
\begin{itemize}
\item automatische Inhaltsanalyse und vergleichende Politik sind eine gute Kombination
\item Länder produzieren Texte in noch nie dagewesenem Umfang
\item traditionelle Regierungsstatistiken sind häufig nicht vorhanden, unvollständig, manipuliert oder falsch gemessen 
\begin{itemize}
\item Regierungen produzieren allerdings große Mengen an Textdaten, welche für deskriptive und kausale Inferenzen genutzt werden können
\item Anreiz für Gelehrte andere Formen von Data zu verwenden
\end{itemize}
\item Gelehrte der vergleichenden Regierungslehre/Politik verwenden bereits automatische Methoden für Textanalysen
\begin{itemize}
\item weitverbreiteste Form von Text zu Politiker sind wahrscheinlich Aufzeichnungen von Reden oder anderen Statements
\end{itemize}
\item Auflistung einiger interessanten Studien die automatische Textanalyse ultilisiert haben
\end{itemize}
\subsection{Text Processing Basics: A Multilanguage View}
\label{sec:org99f934c}
\begin{itemize}
\item Analytiker muss zuerst sicherstellen das zu analysierender Text maschinell lesbar ist
\begin{itemize}
\item statistische Methoden der Textanalyse sind meist unabhängig von der Sprache
\begin{itemize}
\item aber Tools des Prepocessings \emph{nicht}
\end{itemize}
\end{itemize}
\end{itemize}

3 Herausforderungen bei der Arbeit mit verschiedenen Sprachen:
\begin{enumerate}
\item Umgang mit Zeichenkodierung (dealing with encodings)
\item Präprozessing zur Reduktion der Dimensionalität
\item Umgang mit großen Korpora
\end{enumerate}
\subsection{Umgang mit Encodings}
\label{sec:org4c43669}
\begin{itemize}
\item Sprachen können unterschiedliche Zeichenkodierung haben und unterschiedliche Computer händeln dies auf underschiedliche Art \& Weise
\begin{itemize}
\item unterschiedliche default encodings
\end{itemize}
\item wenn der Analyst Daten aus versch Quellen bezieht ist es von nöten, dass das Encoding angepasst wird, sodass es in allen Dokumenten gleich ist 
\begin{itemize}
\item anschließend muss sichergestellt werden, dass die Software die Zeichenkodierung korrekt liest
\end{itemize}
\end{itemize}

\subsection{Prepocessing to extract the most information}
\label{sec:org8a34929}
\subsubsection{Stopword removal}
\label{sec:orga6d8710}
\begin{itemize}
\item Entfernung von Worten die extrem häufig auftreten aber nicht relevant im Bezug auf das Erkenntnisinteresse sind (zb "and", "the", "und", "zum")
\begin{itemize}
\item viele Sprachen haben eine Liste üblicher stop words
\end{itemize}
\item eine Liste von stop words die entfernt werden, sollte sorgfältig gewählt werden, da unterschiedliche stop words zu unterschiedlichen Ergebnissen führen können und manchmal im Kontext entscheidend sein können
\end{itemize}
\subsubsection{Stemming \& lemmatization}
\label{sec:orgadbecc3}
Stemming:
\begin{itemize}
\item Entfernung der Enden von konjugierten Verben oder Nomen in der Pluralform, so dass nur der "Stamm" überbleibt
\item nützlich in jeder Sprache in der das Ende von Worten geändert wird für eine Veränderung der Zeit oder Anzahl (Englisch, Spanisch, Französisch etc)
\item nicht in jeder Sprache nötig/nützlich
\begin{itemize}
\item chinesische Verben werden zB nicht konjugiert und Nomen in chinesisch werden nicht durch eine Endung pluralisiert
\end{itemize}
\item Nützlichkeit ist anwendungs- und sprachabhängig
\item Stemming ist ein Vefahren/Näherung an ein allgemeineres Ziel was als Lemmatization (Lemmatisierung) bezeichnet wird
\end{itemize}

Lemmatization:
\begin{itemize}
\item Identifikation der Grundform eines Wortes und Gruppierung dieser Worte
\item komplexer Algorithmus, der nicht einfach das Ende eines Wortes abschneidet, sondern die Herkunft des Wortes identifiziert und nur das Lemma (Grundform) des Wortes zurück gibt
\item kann außerdem Kontext schlussfolgern:
\begin{itemize}
\item zB "saw" als Nomen = "Säge" bleibt so, als Verb = "sah" wird zu \(\rightarrow\) "sehen/see"
\end{itemize}

\item für Englisch funktioniert Stemming fast so gut wie Lemmatization in anderen Sprachen wie zB Koreanisch oder Türkisch ist Lemmatization hilfreicher
\end{itemize}

\subsubsection{Compound words}
\label{sec:org30751ed}
\begin{itemize}
\item einige (compound) Sprachen setzen oft Worte zusammen (compounding) um ein neues Wort zu bilden zB Kirche + Rat = Kirchenrat
\begin{itemize}
\item decompounding macht in diesem Fall keinen Sinn da die Worte zusammengehören
\end{itemize}
\item in decompoung Sprachen widerrum können \emph{mehrere} getrennte Worte zu \emph{einem} Konzept gehören:
\begin{itemize}
\item "social security" und "national security"
\begin{itemize}
\item beide enthalten "security" aber haben trotzdem unterschiedliche Bedeutung, daher möchte der Analyst die Worte evtl. compounden (zusammenführen), zu "nationalsecurity" und "socialsecurity", um die Bedeutung an \emph{ein} Wort zu koppeln
\end{itemize}
\end{itemize}
\end{itemize}

\subsubsection{Segmentation}
\label{sec:org331c971}
\begin{itemize}
\item einige Sprachen wie zB Chinesisch werden nicht durch Leerzeichen segmentiert und erfordern deshalb automatische Segmentierung bevor sie von einem Statistikprogramm weiterverarbeitet werden können
\end{itemize}

\subsection{Building the document-term matrix}
\label{sec:orgecdf53c}
\begin{itemize}
\item nach dem das Prepocessing abgeschlossen ist, werden die übrig gebliebenen Worte genutzt, um eine document-term matrix (DTM) zu konstruieren
\item in einer document-term matrix repräsentiert jede Reihe ein Dokument und jede Spalte ein ein einzigartiges Wort
\begin{itemize}
\item jede Zelle enthält die Anzahl des Auftreten des jeweiligen Wortes (Spalte) im jeweiligen Dokument (Reihe)
\begin{itemize}
\item üblicherweise enthalten viele Zellen eine 0
\end{itemize}
\end{itemize}
\end{itemize}

Beispiel:
\begin{center}
\begin{tabular}{rrrr}
Berlin & Brüssel & Merkel & Schulz\\
0 & 1 & 0 & 1\\
1 & 0 & 1 & 0\\
\end{tabular}
\end{center}

\begin{itemize}
\item Reihenfolge der Worte beachtet die DTM nicht
\item da diese DTM schon bei Korpora moderater Größe sehr groß werden kann, ist es ratsam nur Einträge zu speichern die nicht 0 sind (sparse representation)
\item die DTM oder ihre sparse representation sind der primäre Input für automatische Textanalysemethoden
\end{itemize}
\subsection{Multilanguage Preprocessing Tools}
\label{sec:org35cf0ba}
\subsubsection{Language-specific processing}
\label{sec:orgae7009f}
\begin{itemize}
\item das R Package `tm` kann Stemming für 11 und stop words removal für 13 Sprachen durchführen
\item die Python basierde Applikaton `txtorg` unterstützt 32 Sprachen
\begin{itemize}
\item alle Sprachen durchlaufen Schritte des best-practice preprocessing
\begin{itemize}
\item geeignete Kombination von Stemming, Segmentation und stop-word Entfernung
\end{itemize}
\end{itemize}
\end{itemize}
\subsubsection{Translation}
\label{sec:org9c402a9}
\begin{itemize}
\item Übersetzung der Dokumente in 1 Sprache kann sich als effizient und zugänglicher für den Nutzer erweisen
\item cross-lingual comparison wird so gut wie nirgends unterstützt
\item Empfehlung: R package `translateR` gibt Zugang zu sehr ausgereiften Übersetzungssystemen (jene die produziert sind von Google und Microsoft)
\end{itemize}

\section{Computer-Assisted Text Analysis}
\label{sec:orgd9f30c1}
\subsection{A Brief Overview of Approaches}
\label{sec:org4e91c23}
zwei Herangehensweisen im Hinblick auf automatische Textanalyse:
\begin{enumerate}
\item supervised methods:
\begin{itemize}
\item "specify what is conceptually interesting about documents in advance, and then the model seeks to extend our insights to a larger population of unseen documents"
\item bspw. manuelle Unterteilung/Klassifizierung von 100 Dokumenten in 2 Kategorien \(\rightarrow\) und dann automatische Klassifizierung der verbleibenden 9900
\end{itemize}
\item unsupervised methods:
\begin{itemize}
\item zB topic modeling
\item keine manuelle Klassifizierung der Texte im Voraus
\item das Modell wird benutzt um eine "low-dimensional summary" zu finden, welche die Dokumente am besten erklärt im Hinblick auf zuvor formulierte Annahmen
\end{itemize}
\end{enumerate}

bei supervised methods liegt der Großteil der von Hand zu verrichtenden Arbeit in der Konstruktion des training sets, bei unsupervised in der Interpretation der model results

Autoren benutzen ein bestimmten Typ des unsupervised topic modeling, welches auf dem Latent Dirichlet Allocation (LDA) model basiert
\begin{itemize}
\item LDA = mixed-mempership model
\begin{itemize}
\item d.h jedes Dokument wird repräsentiert als eine Kombination/Mischung aus einem Pool von Themen und jedem Wort, welchem ebenfalls ein bestimmtes Thema zugewiesen wird
\end{itemize}
\item each topic is a distribution over the words in the vocabulary
\begin{itemize}
\item dies wird gelernt und nicht vom model angenommen
\end{itemize}
\end{itemize}

\subsection{Multilangual Text Modeling}
\label{sec:org0491978}
Herangehensweisen:
\begin{enumerate}
\item Analyse in der nativen Sprache des Textes
\begin{itemize}
\item machbar bei supervised Vorgehen (trotzdem aufwändig), aber keine klare Methodik für unsupervised Vorgehen
\end{itemize}
\item Übersetzung der Texte in eine common Sprache
\begin{itemize}
\item manuelle Übersetzung extrem teuer, daher maschinelle Übersetzung
\end{itemize}
\item Explicit multilangual representation
\begin{itemize}
\item develop a model which maintains an explicitly multilingual representation
\item Vereinheitlichung der konzeptuellen Models über die versch Sprachen hinweg, sodass scaling und Themen (topics) in der einen Sprache vergleichbar mit den Repräsentationen der anderen Sprache sind
\end{itemize}
\end{enumerate}

Übereinstimmung(Korrespondenz) mehrsprachiger Topics hängt von \emph{particular alignment informations} des Anwenders ab und muss (manuell) validiert werden
\begin{itemize}
\item für jedes Topic muss überprüft werden, dass topic word distributions über die Sprachen hinweg einheitlich sind
\end{itemize}
\subsection{The STM}
\label{sec:orgf72c7f9}
\begin{itemize}
\item das STM Framework ist ein mixded-membership topic model (so wie LDA) mit dem Zusatz, dass es dokumentabhängige Metadaten berücksichtigen und mit einbeziehen kann
\begin{itemize}
\item kann Qualität der erlernten Topics erhöhen und Hypothesentests erleichtern
\item erhältlich über das R package `stm`
\end{itemize}
\end{itemize}
\subsubsection{Rolle von Covariates (unabhängigen Variablen)}
\label{sec:orgfd41c50}
\begin{itemize}
\item STM kann im Gegensatz zu LDA "include document-level covariates in the model as a method for pooling information"
\end{itemize}
\subsubsection{Topic correlations}
\label{sec:orgf2a1232}
\begin{itemize}
\item STM kann darüberhinaus die Korrelation von Themen explizit kalkulieren
\end{itemize}

\section{Applications}
\label{sec:org3e99371}
Vorstellung von 2 Anwendungsbereichen des STM
\begin{enumerate}
\item Analyse von islam. \emph{fatwas} in nativer Sprache
\item Analyse von Texten in 2 Sprachen (Arabisch \& Chinsesisch)
\end{enumerate}
\subsection{Jihadi Fatwas}
\label{sec:org3fb0c25}
Kombination von Daten über musl. Gelehrte und Kodierungen im Bezug darauf ob Gelehrte Jihadisten sind, um herauszufinden wie der Themensinhalt von Texten die von jihadist. Gelehrten sich von Nichtjihadisten unterscheiden:
\begin{enumerate}
\item Data von Nielsen: Daten über das Leben und Schriften von 101 bekannten jihad. und nicht-jihad. musl. Gelehrten inklusive 27.248 Texte von diesen
\begin{itemize}
\item Großteil dieser Texte sind fatwas
\item aber auch Bücher, Artikel und Schriften
\item diese Texte zeigen wie Gelehrte mit religiösen Konstitutionen(Wählerschichten?) interagieren
\end{itemize}
\item Unabhängige Kodierungen ob diese Gelehrten Jihadistens sind
\item 2 Quellen:
\begin{itemize}
\item \emph{Militant Ideology Atlas} = führt 56 Individuen an die regelmäßig/oft von Jihadisten zitiert werden
\item Auflistung von bekannten Gelehrten in 8 ideologischen Kategorieren (Jarret Brachman):
\begin{itemize}
\item Salafist, Madkhali Salafist, Albani Salafist, scientific Salafist, Salafist Ikhwan, Sururis, \textbf{Qutubis} und \textbf{Global Jidahist}
\begin{itemize}
\item die letzten 2 Kategorien werden als Jihadisten eingeordnet, die anderen nicht
\end{itemize}
\end{itemize}
\item zusammen ergeben diese beiden Quellen Assesments von 33 der Gelehrten (20 Jihadisten, 13 Nichtjihadisten) zu denen Nielsen 11.045 Texte gesammelt hat
\end{itemize}
\end{enumerate}

detailliertes Vorgehen und Ergebnisse auf Seite 11 - 15
\subsection{Reaktionen auf Snowden in China und in Nahost}
\label{sec:org1e5935b}
\begin{itemize}
\item illustratives Beispiel das zeigt wie maschinelle Übersetzung genutzt zsm mit STM werden kann um Vergleiche über Länder und Sprachen hinweg anzustellen
\item es sei wichtig zu verstehen wie andere Länder die USA finden/bewerten
\begin{itemize}
\item eine Möglichkeit um dies rauszufinden ist mit Hilfe eines Vergleichs von Responses zu bestimmten Ereignissen
\end{itemize}
\item Sammlung von tausenden Social Media Posts in Arabisch \& Chinesisch im Juni 2013, dem Monat als Edward Snowden die Whistle geblowt hat
\begin{itemize}
\item Fokus auf Antworten aus China und Nahost (wichtige strateg. Regionen für die USA)
\end{itemize}
\end{itemize}
\subsubsection{Two approaches to machine translation}
\label{sec:org7b75182}
\begin{itemize}
\item idealerweise Analyse der beiden Datensätze im selben topic model
\begin{itemize}
\item ohne zu übersetzen würde es allerdings keine (vokabularen) Überschneidungen geben
\begin{itemize}
\item dann hätte jeder Korpus eigene indivuelle Topics weil "Snowden" auf Arabisch /neq "Snowden" auf Chinesisch (aber beide selbes Topic "Snowden") und Inhaltsvergleich der Themen somit nicht realisierbar
\end{itemize}
\end{itemize}
\end{itemize}

daher Übersetzung der gesamten Korpora, sowie Übersetzung von Begriffen der DTM mit Hilfe von Google Translate durch `translateR`
\begin{itemize}
\item ersteres weil beim gesamten Text der Kontext fuer die Übersetzung erhalten bleibt
\item zweiteres weil es nur die minimal benötigten Worte (am meisten relevant) übersetzt
\begin{itemize}
\item individuelle Erstellung der DTM für jede Sprache \(\rightarrow\) Übersetzung der jeweiligen Terms \(\rightarrow\) Merge der übersetzten DTM's
\end{itemize}
\item Sicherstellen das kein Topic exklusiv im Kontext einer Sprache existiert
\end{itemize}
\subsubsection{Correcting for systematic differences between languages}
\label{sec:org54d4b12}
\begin{itemize}
\item words that mean the same thing in the Chinese and Arabic corpus could sometimes map onto different words in English that are synonyms of each other
\end{itemize}

\(\rightarrow\) "Within the STM, we can use a content covariate to capture variations in word use attributable to observed covariates. Here we include the document's original language as a content covariate in order to capture linguistic differences in describing a topic. This allows us to effectively marginalize over differences in word rate use that arise due to linguistic differences or errors in translation"
\subsubsection{Results}
\label{sec:orgb1f3e15}
detailliertes Vorgehen \& Ergebnisse auf Seite 17 - 21
\section{Conclusion}
\label{sec:org140f689}
Seite 21 - 22 nicht so relevant da nur eine Zusammenfassung des bereits aufgeführten Vorgehens
\end{document}
